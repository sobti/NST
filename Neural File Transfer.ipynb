{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmC+ycnnG0ppT47o7vpC2h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sobti/NST/blob/main/Neural%20File%20Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk3J5sfrnu1A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=datasets.MNIST(root='data',download=True,transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJI4p5YuoEdJ",
        "outputId": "9960dc8a-1097-4a3f-b4b1-cc279a059259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.76MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.5MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.06MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader=DataLoader(data,batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "I68GpB-QpyUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learn tuple , set , dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMPlPrbDp1S-",
        "outputId": "d0201292-7f56-4378-d595-1ec5174f4a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sequential=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3),\n",
        "        nn.BatchNorm2d(num_features=32),\n",
        "        nn.ReLU())\n",
        "        self.sequential1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3),\n",
        "        nn.BatchNorm2d(num_features=64),\n",
        "        nn.ReLU())\n",
        "        self.pool=nn.MaxPool2d(2)\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.linear1=nn.Linear(in_features=64*5*5,out_features=10)\n",
        "        self.softmax=nn.Softmax()\n",
        "    def forward(self,x):\n",
        "        x=self.sequential(x)\n",
        "        x=self.pool(x)\n",
        "        x=self.sequential1(x)\n",
        "        x=self.pool(x)\n",
        "        x=self.flatten(x)\n",
        "        x=self.softmax(self.linear1(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2_IWq3XDqRjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "import torchsummary as torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTs7HsL6_R_u",
        "outputId": "acb1c8ff-33b7-43f5-a389-ef1dde247dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(model(),(1,28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c53GHzHdAP0N",
        "outputId": "e380f28f-2c16-451b-d153-fb9c8ce8b558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             320\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "              ReLU-3           [-1, 32, 26, 26]               0\n",
            "         MaxPool2d-4           [-1, 32, 13, 13]               0\n",
            "            Conv2d-5           [-1, 64, 11, 11]          18,496\n",
            "       BatchNorm2d-6           [-1, 64, 11, 11]             128\n",
            "              ReLU-7           [-1, 64, 11, 11]               0\n",
            "         MaxPool2d-8             [-1, 64, 5, 5]               0\n",
            "           Flatten-9                 [-1, 1600]               0\n",
            "           Linear-10                   [-1, 10]          16,010\n",
            "          Softmax-11                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 35,018\n",
            "Trainable params: 35,018\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.74\n",
            "Params size (MB): 0.13\n",
            "Estimated Total Size (MB): 0.87\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch as torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "g43LcJ6ekzsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=torchvision.models.vgg19(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbL9ciBslBvX",
        "outputId": "2586d4b0-d314-4ea9-ebe3-6189e74f0257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:06<00:00, 82.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG, self).__init__()\n",
        "    self.select_features = ['0', '5', '10', '19', '28'] #conv layers\n",
        "    self.vgg = torchvision.models.vgg19(pretrained=True).features\n",
        "    print(self.vgg)\n",
        "\n",
        "  def forward(self, output):\n",
        "    features = []\n",
        "    for name, layer in self.vgg._modules.items():\n",
        "      output = layer(output)\n",
        "      if name in self.select_features:\n",
        "        features.append(output)\n",
        "    return features\n",
        "\n",
        "#load the model\n",
        "vgg = VGG()"
      ],
      "metadata": {
        "id": "cxqYUfT0Gf8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self, target):\n",
        "        super().__init__()\n",
        "        self.target = target.detach()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.loss = nn.functional.mse_loss(x, self.target)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UdKMAAtOmnU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "content_img=' '\n",
        "new=nn.Sequential()\n",
        "for layer in model.features.children():\n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        i += 1\n",
        "        new.add_module(f\"Cov2d_{i}\", layer)\n",
        "        target=new(content_img)\n",
        "        loss=ContentLoss(target)\n",
        "        new.add_module(f\"content_loss_{i}\", loss)\n"
      ],
      "metadata": {
        "id": "L8ny7o5UpOMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg=torchvision.models.vgg19(pretrained=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n_vBH3sDphHV",
        "outputId": "23e66cc7-20bb-4e36-df8e-de96d80653b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class content_loss(nn.Module):\n",
        "    def __init__(self,target):\n",
        "        super().__init__()\n",
        "        self.target=target.detach()\n",
        "    def forward(self,x):\n",
        "        self.loss=nn.functional.mse_loss(x,self.target)\n",
        "        return x"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XrjLrMhRwU1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def myfunc():\n",
        " new_model=nn.Sequential()\n",
        " i=0\n",
        " content_img=torch.randn(1,3,224,224)\n",
        " for layer in vgg.features:\n",
        "    if isinstance(layer,nn.Conv2d):\n",
        "        i += 1\n",
        "        name=f\"conv_{i}\"\n",
        "        new_model.add_module(name,layer)\n",
        "    elif isinstance(layer,nn.ReLU):\n",
        "        name=f\"relu_{i}\"\n",
        "        new_model.add_module(name,nn.ReLU())\n",
        "    elif isinstance(layer,nn.MaxPool2d):\n",
        "        name=f\"maxpool_{i}\"\n",
        "        new_model.add_module(name,layer)\n",
        "    else: continue\n",
        "\n",
        "    if  name in ['conv_1','conv_2','conv_3','conv_4','conv_5']:\n",
        "        target=new_model(content_img)\n",
        "        loss=content_loss(target)\n",
        "        new_model.add_module(f\"content_loss_{i}\",loss)\n",
        " return new_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e6RNFJ6ZwoFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=myfunc()"
      ],
      "metadata": {
        "id": "taNsg9Zlxq-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.randn(1,3,224,224))"
      ],
      "metadata": {
        "id": "mJCTZaLqCbzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "import numpy\n",
        "import torch.optim as optimization\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "065tn6EZ1U7C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: open file from \"/content/style_image.jpg\"\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ULwUTbmQ4T9x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "72myW_CZ4myz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style_img = Image.open(\"/content/style.jpg\")\n",
        "transform_image=transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize((0.6971, 0.7078, 0.6860),(0.2333, 0.2431, 0.3146))])\n",
        "style_image=transform_image(style_img)\n",
        "content_img=transform_image(content_img)\n",
        "target_img = content_img.clone().requires_grad_(True)"
      ],
      "metadata": {
        "id": "EPDlGq1mWifT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVQtpih9Wwp5",
        "outputId": "bc487319-c819-41a3-b3fc-0a76fe86c947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg=torchvision.models.vgg19(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg=vgg.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHz9wD6P5iTg",
        "outputId": "2038ee2d-6720-454d-ef28-5d98d8b750cb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def content_loss(x,target):\n",
        "        loss=nn.functional.mse_loss(x,target)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "4FMClvaE8BFb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_matrix(x):\n",
        "        a,b,c,d=x.size()\n",
        "        x=x.view(a*b,c*d)\n",
        "        gram=torch.mm(x,x.t())\n",
        "        return gram/b*c*d"
      ],
      "metadata": {
        "id": "Z8uBMpZO9b3E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def style_loss(x,target):\n",
        "        loss=nn.functional.mse_loss(gram_matrix(x),gram_matrix(target))\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "MJ7K7cJf-HtM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_layers=['conv_1','conv_5','conv_10','conv_15','conv_20']\n",
        "style_layers=['conv_1','conv_5','conv_10','conv_15','conv_20']"
      ],
      "metadata": {
        "id": "vL7LNCgQWJOR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_and_loss(cnn):\n",
        "        cnn = cnn.eval()\n",
        "        new_model=nn.Sequential()\n",
        "        i=0\n",
        "        for layer in cnn.features.children():\n",
        "            if isinstance(layer,nn.Conv2d):\n",
        "                i += 1\n",
        "                name=f\"conv_{i}\"\n",
        "                new_model.add_module(name,layer)\n",
        "            elif isinstance(layer,nn.ReLU):\n",
        "                name=f\"relu_{i}\"\n",
        "                new_model.add_module(name,nn.ReLU())\n",
        "            elif isinstance(layer,nn.MaxPool2d):\n",
        "                name=f\"maxpool_{i}\"\n",
        "                new_model.add_module(name,layer)\n",
        "            else: continue\n",
        "\n",
        "        return new_model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jR500G75AG_0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=get_model_and_loss(vgg).to(device)"
      ],
      "metadata": {
        "id": "5dXA9_CeGBRZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(output):\n",
        "    content_features=[]\n",
        "    for layer in model.named_children():\n",
        "        output=layer[1](output)\n",
        "        if layer[0] in content_layers:\n",
        "            content_features.append(output)\n",
        "    return content_features"
      ],
      "metadata": {
        "id": "tq5EjtztTvLN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "NLb-rxQydehp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def style_transfer(content_img):\n",
        "  target_feature=[]\n",
        "  style_img = Image.open(\"/content/style.jpeg\")\n",
        "  transform_image=transforms.Compose([transforms.Resize((512,512)),transforms.ToTensor()])\n",
        "\n",
        "  style_image=transform_image(style_img)\n",
        "\n",
        "  content_img=transform_image(content_img)\n",
        "\n",
        "  target_img = content_img.clone().requires_grad_(True)\n",
        "\n",
        "  optimizer=optimization.Adam([target_img],lr=0.003)\n",
        "\n",
        "  content_feature = []\n",
        "\n",
        "  style_feature = []\n",
        "\n",
        "\n",
        "\n",
        "  for step in tqdm(range(3000)):\n",
        "   #get feature vectors representations for every image\n",
        "   content_feature = get_features(content_img.unsqueeze(0).to('cuda'))\n",
        "   style_feature = get_features(style_image.unsqueeze(0).to('cuda'))\n",
        "   target_feature = get_features(target_img.unsqueeze(0).to('cuda'))\n",
        "\n",
        "\n",
        "   #initiate the losses\n",
        "   current_style_loss = 0\n",
        "   current_content_loss = 0\n",
        "\n",
        "   for target, content, style in zip(target_feature, content_feature, style_feature):\n",
        "     current_content_loss += content_loss(target, content)\n",
        "     current_style_loss += style_loss(target, style)\n",
        "\n",
        "   #calculate the total loss according to the original paper\n",
        "   total_loss = current_content_loss+10000000*current_style_loss\n",
        "\n",
        "   #set parameters to zero\n",
        "   optimizer.zero_grad()\n",
        "   #compute the gradient\n",
        "   total_loss.backward()\n",
        "   #update parameters\n",
        "   optimizer.step()\n",
        "   #uncomment if you want to follow the progress\n",
        "   #if step%2 == 0:\n",
        "     #print(f'step: {step}, content loss: {current_content_loss}, style loss: {current_style_loss}')\n",
        "  return convert_image(target_img)\n"
      ],
      "metadata": {
        "id": "zLkTczEoY5B-"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.functional import to_pil_image\n",
        "def convert_image(img):\n",
        "\n",
        "\n",
        "# Ensure tensor is on CPU and detached from computation graph\n",
        " tensor = img.detach().cpu()\n",
        "\n",
        " image = to_pil_image(tensor)\n",
        " return image"
      ],
      "metadata": {
        "id": "M3SgJLNslLyz"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuOgB2yXngvA",
        "outputId": "37cb3d84-c753-44b4-dcd4-e1608e0be39d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.30.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.1 (from gradio)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.30.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.30.0 gradio-client-1.10.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    fn=style_transfer,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Content Image\"),\n",
        "    ],\n",
        "    outputs=gr.Image(label=\"Stylized Output\"),\n",
        "    title=\"Neural Style Transfer\",\n",
        "    description=\"Upload a content image and a style image. The model will blend the content with the style.\"\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "NOlFIsXSmtjK",
        "outputId": "c712b6be-50d2-4b5a-e58d-1fcbc863efe3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c26cb27848206e4ae9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c26cb27848206e4ae9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [15:58<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://c26cb27848206e4ae9.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ]
}